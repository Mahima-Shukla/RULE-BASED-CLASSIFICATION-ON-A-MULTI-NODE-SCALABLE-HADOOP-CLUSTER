# RULE-BASED-CLASSIFICATION-ON-A-MULTI-NODE-SCALABLE-HADOOP-CLUSTER
Hadoop framework is one of the reliable, scalable framework for the big data analytics. In this project we investigate the Hadoop frame-work for distributed data mining to reduce the computational cost for the exponentially growing scientiﬁc data. We use the RIPPER (Repeated Incremental Pruning for Error Reduction) algorithm to develop a rule based classiﬁer. Computational power is increasing with time. However, the requirement to process the everyday generated data are still challenging. Moreover, the data is distributed all over the globe. Significant technological advancements have paved way for cost-effective parallel computing system. Hence, there is a sudden increase in the importance of parallel and distributed computing. We propose a parallel implementation of RIPPER based on the Hadoop MapReduce framework. The data is horizontally partitioned so that each node operates on a portion of the dataset and ﬁnally the results are aggregated to develop the classiﬁer. We will test our algorithm on datasets and results will be evaluated.
